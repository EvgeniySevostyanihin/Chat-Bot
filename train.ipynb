{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model import Encoder, AttentionDecoder, EMBEDDING_SIZE, SOS_token\n",
    "import random\n",
    "from prepared import load_voc, batch2train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "data, Vocabulary = load_voc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных, для использования в модели\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "inp, lenghts, target, mask, max_target_len = batch2train_data([random.choice(data) for _ in range(2)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7, 2])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([27, 2])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "35691"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocabulary.num_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(2**16, EMBEDDING_SIZE)\n",
    "encoder = Encoder(embedding)\n",
    "decoder = AttentionDecoder(embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "65536"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.num_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "decoder_input = torch.ones(64).view((1, 64)).long()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "training_batches = [batch2train_data([random.choice(data) for _ in range(64)]) for _ in range(128)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "inp, lenghts, out, mask, max_target_lenght = training_batches[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 64])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "['ну так скажите  куда мы  по вашему  едем ',\n 'куда  куда  тебе что  услышать хочется лишний раз  ясное дело  куда  к разрушенному мосту  что ты себе смолоду такой херней голову забиваешь  андрюха ']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "encoder_out, encoder_hidden = encoder(inp, lenghts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.3761, -0.9388, -0.7662,  ..., -0.7292,  0.2528, -1.5036],\n         [ 0.2781,  2.2181, -1.8477,  ..., -2.2462,  0.6356,  0.6831],\n         [-0.9759,  0.1534, -0.1476,  ...,  0.4621, -0.5021,  1.0112],\n         ...,\n         [ 0.6782, -0.0552, -0.0959,  ...,  1.1213, -1.1809,  0.8640],\n         [-0.0207,  1.5888, -0.3059,  ..., -0.2259,  0.9216,  0.5446],\n         [-1.6445,  0.5777, -1.7869,  ...,  0.1063,  0.5181, -0.1051]],\n\n        [[ 0.4501, -0.1442, -1.1952,  ...,  1.9488,  0.8456,  0.3391],\n         [-0.6323,  1.2789,  1.0246,  ...,  0.3898,  0.4185,  0.7187],\n         [-1.5673, -1.2672,  0.1128,  ..., -0.6350,  0.6364,  0.5654],\n         ...,\n         [ 0.3034, -0.3745,  0.0764,  ...,  0.4210,  0.0210,  1.2462],\n         [ 1.6393,  0.1444,  1.2381,  ...,  0.1740, -0.6929, -0.0708],\n         [ 1.6393,  0.1444,  1.2381,  ...,  0.1740, -0.6929, -0.0708]],\n\n        [[-0.0659,  0.6104, -1.6969,  ..., -0.0707,  0.9871,  1.8567],\n         [ 0.6835, -1.0751, -0.2272,  ..., -1.8918, -0.7827,  1.7687],\n         [-0.0687,  0.6607,  0.8949,  ..., -0.6109, -0.8008, -0.5171],\n         ...,\n         [ 1.6393,  0.1444,  1.2381,  ...,  0.1740, -0.6929, -0.0708],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906]],\n\n        ...,\n\n        [[ 0.3034, -0.3745,  0.0764,  ...,  0.4210,  0.0210,  1.2462],\n         [ 0.3034, -0.3745,  0.0764,  ...,  0.4210,  0.0210,  1.2462],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         ...,\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906]],\n\n        [[ 0.3034, -0.3745,  0.0764,  ...,  0.4210,  0.0210,  1.2462],\n         [ 1.6393,  0.1444,  1.2381,  ...,  0.1740, -0.6929, -0.0708],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         ...,\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906]],\n\n        [[ 1.6393,  0.1444,  1.2381,  ...,  0.1740, -0.6929, -0.0708],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         ...,\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906],\n         [ 0.0231, -0.9295,  2.6365,  ...,  0.3142, -0.9196, -0.5906]]],\n       grad_fn=<EmbeddingBackward>)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(inp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   80,     9,   710,  ...,  1161,   582, 30543],\n        [  127,   272, 12638,  ...,     4,     2,     2],\n        [   39,  1126, 15353,  ...,     2,     0,     0],\n        ...,\n        [    4,     4,     0,  ...,     0,     0,     0],\n        [    4,     2,     0,  ...,     0,     0,     0],\n        [    2,     0,     0,  ...,     0,     0,     0]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 64, 128])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden[:2].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 64, 128])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.4556e-05, 1.5725e-05, 1.4634e-05,  ..., 1.5478e-05, 1.4346e-05,\n          1.5756e-05],\n         [1.3723e-05, 1.6123e-05, 1.5011e-05,  ..., 1.6184e-05, 1.4667e-05,\n          1.6344e-05],\n         [1.4097e-05, 1.6384e-05, 1.5196e-05,  ..., 1.4237e-05, 1.4292e-05,\n          1.5084e-05],\n         ...,\n         [1.3370e-05, 1.6301e-05, 1.5298e-05,  ..., 1.6102e-05, 1.3937e-05,\n          1.5765e-05],\n         [1.3563e-05, 1.5556e-05, 1.6594e-05,  ..., 1.4885e-05, 1.4375e-05,\n          1.5212e-05],\n         [1.4848e-05, 1.6134e-05, 1.7080e-05,  ..., 1.6174e-05, 1.4911e-05,\n          1.4783e-05]], grad_fn=<SoftmaxBackward>),\n tensor([[[ 1.8600e-01, -1.7920e-01, -2.0808e-01,  ..., -5.7619e-01,\n            4.3289e-01,  3.3865e-01],\n          [ 3.8053e-01, -4.2061e-02, -1.6946e-01,  ..., -6.6075e-01,\n            5.8597e-01,  7.0384e-03],\n          [-2.8307e-02,  4.2333e-01, -4.0583e-02,  ..., -3.7236e-01,\n            2.6082e-01,  3.1713e-01],\n          ...,\n          [ 8.5236e-02,  1.9773e-01, -2.3337e-01,  ..., -6.4242e-01,\n            5.4825e-01,  2.6233e-01],\n          [-2.4503e-01, -9.4144e-02,  4.9702e-01,  ..., -4.6458e-01,\n            1.1824e-01, -3.6971e-01],\n          [-2.0898e-01,  1.7400e-01,  3.0834e-02,  ..., -5.7187e-01,\n            6.9112e-01,  2.1537e-01]],\n \n         [[ 8.7912e-02,  3.9194e-01,  1.0881e-01,  ...,  2.4973e-01,\n            9.0317e-02,  2.1392e-01],\n          [-5.9931e-02,  3.8022e-02, -1.6899e-01,  ..., -2.7248e-01,\n            2.3798e-01,  1.1303e-01],\n          [-2.1679e-01, -8.9598e-02, -1.8550e-01,  ..., -2.8924e-01,\n           -5.4776e-02, -6.5477e-02],\n          ...,\n          [ 5.9644e-02, -1.5476e-01,  5.4754e-02,  ...,  9.7379e-02,\n            5.1118e-02,  1.7503e-01],\n          [-1.7873e-01, -3.2001e-04,  1.7937e-02,  ...,  7.3879e-02,\n            1.7150e-01,  1.3482e-01],\n          [-1.6714e-01,  5.5885e-03, -2.4632e-02,  ..., -3.3687e-01,\n           -2.8400e-02,  6.7275e-02]]], grad_fn=<StackBackward>))"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(decoder_input, encoder_hidden[:2], encoder_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "embed = embedding(decoder_input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "embed, hidden = decoder.gru(embed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0258, -0.1106, -0.0412,  ...,  0.0154,  0.0369,  0.1458],\n         [-0.0294, -0.1166,  0.0214,  ..., -0.0258,  0.0208,  0.1486],\n         [-0.0536,  0.0036, -0.0253,  ...,  0.0428,  0.0175,  0.0770],\n         ...,\n         [-0.0633, -0.0350, -0.0175,  ..., -0.0289,  0.1048,  0.1651],\n         [-0.0267,  0.0866, -0.0254,  ..., -0.0310, -0.0892,  0.1229],\n         [ 0.0429, -0.0371, -0.0593,  ..., -0.0896, -0.0579,  0.1566]]],\n       grad_fn=<StackBackward>)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "hidden * "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-86459515",
   "language": "python",
   "display_name": "PyCharm (Emotion-Recognition)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}