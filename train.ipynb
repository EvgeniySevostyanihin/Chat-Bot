{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from model import load_models, Encoder, AttentionDecoder, EMBEDDING_SIZE\n",
    "import random\n",
    "from prepared import load_voc, batch2train_data, input_var, indexesFromSentence\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data, Vocabulary = load_voc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "batch_size = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "35691"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocabulary.num_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# embedding = nn.Embedding(2**16, EMBEDDING_SIZE).to(device)\n",
    "# encoder = Encoder(embedding).to(device)\n",
    "# decoder = AttentionDecoder(embedding).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "45000"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder, embedding = load_models()\n",
    "\n",
    "encoder_optim = Adam(encoder.parameters(), lr=1e-5)\n",
    "decoder_optim = Adam(decoder.parameters(), lr=5e-5)\n",
    "\n",
    "encoder.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calculate_loss(inp, target, mask):\n",
    "\n",
    "    loss = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = loss.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    # для вывода графика\n",
    "    history = []\n",
    "    short_mem = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        # всё стандартно\n",
    "        encoder_optim.zero_grad()\n",
    "        decoder_optim.zero_grad()\n",
    "\n",
    "        inp, lenghts, target, mask, max_target_len = batch2train_data([random.choice(data) \\\n",
    "                                                                       for _ in range(batch_size)])\n",
    "\n",
    "        inp = inp.to(device)\n",
    "        lenghts = lenghts.to(device)\n",
    "        target = target.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # провожу через енкодинг\n",
    "        encoder_out, encoder_hidden = encoder(inp, lenghts)\n",
    "        # начальное значение для работы декодера\n",
    "        decoder_input = torch.ones(batch_size).long().to(device).unsqueeze(0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        decoder_hidden = encoder_hidden[:2]\n",
    "\n",
    "        for i in range(max_target_len):\n",
    "            decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_out)\n",
    "\n",
    "            decoder_input = torch.LongTensor([[decoder_out.topk(1)[1][x][0] for\\\n",
    "                                               x in range(batch_size)]]).to(device)\n",
    "\n",
    "            loss += calculate_loss(decoder_out, target[i], mask[i])\n",
    "\n",
    "        short_mem.append(loss)\n",
    "\n",
    "        if not encoder.epochs % 1000:\n",
    "            print(f'{encoder.epochs}  {loss}')\n",
    "            history.append(torch.tensor(short_mem).mean())\n",
    "            short_mem = []\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "\n",
    "        encoder.epochs += 1\n",
    "\n",
    "        # save model\n",
    "\n",
    "        if not encoder.epochs % 1000:\n",
    "\n",
    "            torch.save(encoder, f\"models/encoder{encoder.epochs}\")\n",
    "            torch.save(decoder, f\"models/decoder{encoder.epochs}\")\n",
    "            torch.save(embedding, f\"models/embedding{encoder.epochs}\")\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000  57.240234375\n",
      "46000  137.4744873046875\n",
      "47000  297.71710205078125\n",
      "48000  816.4173583984375\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train(50000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def greedy_search(sequence, length, maximum=30):\n",
    "    # всё также как на тренировке\n",
    "    encoder_out, encoder_hidden = encoder(sequence, length)\n",
    "\n",
    "    decoder_hidden = encoder_hidden[:2]\n",
    "    decoder_input = torch.ones(1, 1, device=device, dtype=torch.long)\n",
    "    # здесь складываються ответы по жадному методу\n",
    "    all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "    # всего будет 30 оборотов, при выводе отрежуться ненужные токены, а 30, чтобы больше не было\n",
    "    for _ in range(maximum):\n",
    "\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_out)\n",
    "\n",
    "        _, decoder_input = torch.max(decoder_output, dim=1)\n",
    "\n",
    "        all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "\n",
    "        decoder_input = decoder_input.unsqueeze(0)\n",
    "\n",
    "    return all_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "clean = lambda text: \"\".join(x for x in text.lower() if x not in string.punctuation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "Как дела?\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n",
      "\n",
      "Машина > а                             \n"
     ]
    }
   ],
   "source": [
    "while \"Матеша идёт\":\n",
    "\n",
    "    text = input('Я > ')\n",
    "    print(text)\n",
    "    # ввод текста и очистка\n",
    "    text = clean(text)\n",
    "\n",
    "    # перевод в форму для енкодера\n",
    "    text = torch.tensor([indexesFromSentence(text)])\n",
    "    length = torch.tensor([len(text[0])])\n",
    "\n",
    "    text = text.transpose(0, 1).long().to(device)\n",
    "\n",
    "    text = greedy_search(text, length)\n",
    "\n",
    "    text = [Vocabulary.index2word[token.item()] for token in text]\n",
    "\n",
    "    text[:] = [x for x in text if not (x == 'EOS' or x == \"PAD\")]\n",
    "\n",
    "    print(f'Машина > {\" \".join(text)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-86459515",
   "language": "python",
   "display_name": "PyCharm (Emotion-Recognition)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}