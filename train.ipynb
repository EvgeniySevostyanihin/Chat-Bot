{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from model import load_models, Encoder, AttentionDecoder, EMBEDDING_SIZE\n",
    "import random\n",
    "from prepared import load_voc, batch2train_data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data, Vocabulary = load_voc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "batch_size = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "35691"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocabulary.num_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(2**16, EMBEDDING_SIZE).to(device)\n",
    "encoder = Encoder(embedding).to(device)\n",
    "decoder = AttentionDecoder(embedding).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder, decoder, embedding = load_models()\n",
    "\n",
    "encoder_optim = Adam(encoder.parameters(), lr=1e-4)\n",
    "decoder_optim = Adam(decoder.parameters(), lr=5e-4)\n",
    "\n",
    "encoder.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calculate_loss(inp, target, mask):\n",
    "\n",
    "    loss = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = loss.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    # для вывода графика\n",
    "    history = []\n",
    "    short_mem = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        # всё стандартно\n",
    "        encoder_optim.zero_grad()\n",
    "        decoder_optim.zero_grad()\n",
    "\n",
    "        inp, lenghts, target, mask, max_target_len = batch2train_data([random.choice(data) \\\n",
    "                                                                       for _ in range(batch_size)])\n",
    "\n",
    "        inp = inp.to(device)\n",
    "        lenghts = lenghts.to(device)\n",
    "        target = target.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # провожу через енкодинг\n",
    "        encoder_out, encoder_hidden = encoder(inp, lenghts)\n",
    "        # начальное значение для работы декодера\n",
    "        decoder_input = torch.ones(batch_size).long().to(device).unsqueeze(0)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(max_target_len):\n",
    "            decoder_out, decoder_hidden = decoder(decoder_input, encoder_hidden[:2], encoder_out)\n",
    "\n",
    "            decoder_input = torch.LongTensor([[decoder_out.topk(1)[1][x][0] for\\\n",
    "                                               x in range(batch_size)]]).to(device)\n",
    "\n",
    "            loss += calculate_loss(decoder_out, target[i], mask[i])\n",
    "\n",
    "        short_mem.append(loss)\n",
    "\n",
    "        if not encoder.epochs % 500:\n",
    "            print(f'{encoder.epochs}  {loss}')\n",
    "            history.append(torch.tensor(short_mem).mean())\n",
    "            short_mem = []\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "\n",
    "        encoder.epochs += 1\n",
    "\n",
    "        # save model\n",
    "\n",
    "        if not encoder.epochs % 1000:\n",
    "\n",
    "            torch.save(encoder, f\"models/encoder{encoder.epochs}\")\n",
    "            torch.save(decoder, f\"models/decoder{encoder.epochs}\")\n",
    "            torch.save(embedding, f\"models/embedding{encoder.epochs}\")\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  476.6577453613281\n",
      "500  858.7587280273438\n",
      "1000  230.8096160888672\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train(10000) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-86459515",
   "language": "python",
   "display_name": "PyCharm (Emotion-Recognition)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}